{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import numpy as np\n",
    "from skimage import data, color, feature\n",
    "import skimage.data\n",
    "from sklearn.datasets import fetch_lfw_people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(13233, 62, 47)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get images with faces\n",
    "faces = fetch_lfw_people()\n",
    "positive_patches = faces.images # obrazki z twarzami\n",
    "positive_patches.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lewiis\\AppData\\Local\\Temp/ipykernel_8620/577394038.py:9: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\n",
      "  images = [color.rgb2gray(getattr(skimage.data, name)()) # Compute luminance of an RGB image for each image\n"
     ]
    }
   ],
   "source": [
    "# get images without faces\n",
    "from skimage import data, transform\n",
    "\n",
    "imgs_to_use = ['camera', 'text', 'coins', 'moon',\n",
    "               'page', 'clock', 'immunohistochemistry',\n",
    "               'chelsea', 'coffee', 'hubble_deep_field']\n",
    "\n",
    "# skimage.data is set of images\n",
    "images = [color.rgb2gray(getattr(skimage.data, name)()) # Compute luminance of an RGB image for each image\n",
    "          for name in imgs_to_use]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "(30000, 62, 47)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.image import PatchExtractor\n",
    "\n",
    "# rescale negative images\n",
    "def extract_patches(img, N, scale=1.0,\n",
    "                    patch_size=positive_patches[0].shape):\n",
    "    extracted_patch_size = tuple((scale * np.array(patch_size)).astype(int))\n",
    "    extractor = PatchExtractor(patch_size=extracted_patch_size,\n",
    "                               max_patches=N, random_state=0)\n",
    "    patches = extractor.transform(img[np.newaxis])\n",
    "    if scale != 1:\n",
    "        patches = np.array([transform.resize(patch, patch_size)\n",
    "                            for patch in patches])\n",
    "    return patches\n",
    "\n",
    "negative_patches = np.vstack([extract_patches(img, 1000, scale)\n",
    "                              for img in images for scale in [0.5, 1.0, 2.0]])\n",
    "negative_patches.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "X_train = np.array([feature.hog(im)\n",
    "                    for im in chain(positive_patches, negative_patches)]) # extract histograms of oriented gradients\n",
    "\n",
    "y_train = np.zeros(X_train.shape[0])\n",
    "y_train[:positive_patches.shape[0]] = 1 # imgaes with faces are marked as 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# classification model\n",
    "# network architecture\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3,\n",
    "                      padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(64*7*7,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(-1, 64*7*7)\n",
    "        out = self.layer3(out)\n",
    "        return out\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# training loop\n",
    "\n",
    "def train_loop(epochs, optimizer, model, loss_fn, train_loader, val_loader):\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        loss_train = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for imgs, labels in train_loader:\n",
    "\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            total += labels.shape[0]\n",
    "            correct += int((predicted==labels).sum())\n",
    "\n",
    "            train_correct = correct\n",
    "            train_total = total\n",
    "\n",
    "        epoch_list.append(epoch)\n",
    "        train_loss_list.append(loss_train)\n",
    "\n",
    "        # test on validation data\n",
    "        # get loss of validation data\n",
    "        with torch.no_grad():\n",
    "            loss_val = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for imgs, labels in val_loader:\n",
    "                # move tensors to gpu if available\n",
    "                imgs = imgs.to(device=device)\n",
    "                labels = labels.to(device=device)\n",
    "\n",
    "                outputs = model(imgs)\n",
    "\n",
    "                loss_v = loss_fn(outputs, labels)\n",
    "\n",
    "                loss_val += loss_v.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs, dim=1) # Gives us the index of the highest value\n",
    "            total += labels.shape[0]  # Counts the number of examples, so total is increased by the batch size\n",
    "            correct += int((predicted == labels).sum())\n",
    "            val_correct = correct\n",
    "            val_total = total\n",
    "\n",
    "\n",
    "        val_loss_list.append(loss_val / len(val_loader))\n",
    "\n",
    "        train_acc_list.append(train_correct/train_total)\n",
    "        val_acc_list.append(val_correct/val_total)\n",
    "\n",
    "        # set when to print info about training progress\n",
    "        if epoch == 1 or epoch % 1 == 0:\n",
    "            print('Epoch {}, Training loss {:.3f}, Validation loss {:.3f}, Train Acc {:.3f}, Val Acc {:.3f}'.format(epoch, loss_train / len(train_loader), loss_val / len(val_loader), train_correct/train_total, val_correct/val_total),\n",
    "                  )\n",
    "\n",
    "def test_loop(model, test_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in test_loader:\n",
    "\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            _, predicted = torch.max(outputs, dim=1) # Gives us the index of the highest value\n",
    "            total += labels.shape[0]  # Counts the number of examples, so total is increased by the batch size\n",
    "            correct += int((predicted == labels).sum())\n",
    "\n",
    "\n",
    "    print(\"Accuracy test: {:.3f} %\".format(100 *  (correct / total)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# take a test image\n",
    "test_image = skimage.data.astronaut()\n",
    "test_image = skimage.color.rgb2gray(test_image)\n",
    "test_image = skimage.transform.rescale(test_image, 0.5)\n",
    "test_image = test_image[:160, 40:180]\n",
    "plt.imshow(test_image, cmap='gray')\n",
    "plt.axis('off');"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#\n",
    "def sliding_window(img, patch_size=positive_patches[0].shape, istep=2, jstep=2, scale=1.0):\n",
    "    Ni, Nj = (int(scale*s) for s in patch_size)\n",
    "    for i in range(0, img.shape[0] - Ni, istep):\n",
    "        for j in range(0, img.shape[1] - Ni, jstep):\n",
    "            patch = img[i:i + Ni, j:j + Nj]\n",
    "            if scale != 1:\n",
    "                patch = transform.resize(patch, patch_size)\n",
    "            yield (i, j), patch\n",
    "\n",
    "indices, patches = zip(*sliding_window(test_image))\n",
    "patches_hog = np.array([feature.hog(patch) for patch in patches])\n",
    "patches_hog.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels = model.predict(patches_hog)\n",
    "labels.sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(test_image, cmap='gray')\n",
    "ax.axis('off')\n",
    "Ni, Nj = positive_patches[1].shape\n",
    "indices = np.array(indices)\n",
    "\n",
    "i_ind = []\n",
    "j_ind = []\n",
    "for i, j in indices[labels==1]:\n",
    "    i_ind.append(i)\n",
    "    j_ind.append(j)\n",
    "\n",
    "i_ind = np.array(i_ind)\n",
    "j_ind = np.array(j_ind)\n",
    "\n",
    "for i, j in indices[labels==1]:\n",
    "    ax.add_patch(plt.Rectangle((j, i), Nj, Ni, edgecolor='red', alpha=0.3, lw=2, facecolor='none'))\n",
    "# ax.add_patch(plt.Rectangle((i_ind.mean(), j_ind.mean()), Nj, Ni, edgecolor='red', alpha=0.5, lw=3, facecolor='none'))\n",
    "\n",
    "# for i, j in indices[labels == 1]:\n",
    "#     ax.add_patch(plt.Rectangle((j, i), Nj, Ni, edgecolor='red',\n",
    "#                                alpha=0.3, lw=2,\n",
    "#                                facecolor='none'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}